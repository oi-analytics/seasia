{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prompt-grounds",
   "metadata": {},
   "source": [
    "# Post-process ADM1 summary results\n",
    "\n",
    "For loading in oi-risk-vis interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_fnames = glob('../results/summary/*/Cyclone/*.csv')\n",
    "fluvial_fnames = glob('../results/summary/*/Fluvial/*/*.csv')\n",
    "coastal_fnames = glob('../results/summary/*/Coastal/*/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_df(df, id_vars, new_id_vars):\n",
    "    # melt to get a long dataframe with \"variable\" and \"value\"\n",
    "    # columns, where \"variable\" is taken from each input column name\n",
    "    df_tidy = df \\\n",
    "        .reset_index() \\\n",
    "        .melt(id_vars=id_vars)\n",
    "    \n",
    "    # create a column from each new_id_var \n",
    "    # by splitting the \"variable\" names on \"_\"\n",
    "    for i, varname in enumerate(new_id_vars):\n",
    "        df_tidy[varname] = df_tidy.variable.apply(lambda d: d.split(\"_\")[i+1])\n",
    "        \n",
    "    # keep only the first element as the actual variable name \n",
    "    df_tidy['variable'] = df_tidy.variable.apply(lambda d: d.split(\"_\")[0])\n",
    "    \n",
    "    # parse an integer from return period, if present\n",
    "    if 'rp' in new_id_vars:\n",
    "        df_tidy.rp = df_tidy.rp.apply(lambda d: int(d.replace(\"RP\", \"\")))\n",
    "        \n",
    "    # pivot back out to columns for each variable\n",
    "    df_tidy = df_tidy.pivot_table(index=(id_vars + new_id_vars), columns='variable')\n",
    "    df_tidy.columns = [v for _, v in df_tidy.columns]\n",
    "    return df_tidy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_rp_columns(df):\n",
    "    df_rp = df[[c for c in df.columns if 'RP' in c]]\n",
    "    df_exp = df[[c for c in df.columns if 'RP' not in c]]\n",
    "    return df_rp, df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_regroup(df):\n",
    "    rp, exp = split_df_by_rp_columns(df)\n",
    "    exp_tidy = tidy_df(\n",
    "        exp, \n",
    "        id_vars=['region_name', 'sector', 'rcp'],\n",
    "        new_id_vars=['gcm', 'epoch'])\n",
    "    rp_tidy = tidy_df(\n",
    "        rp, \n",
    "        id_vars=['region_name', 'sector', 'rcp'],\n",
    "        new_id_vars=['gcm', 'epoch', 'rp'])\n",
    "    return rp_tidy, exp_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-newfoundland",
   "metadata": {},
   "source": [
    "## Cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for fname in tqdm(cyclone_fnames):    \n",
    "    sector = os.path.basename(os.path.dirname(os.path.dirname(fname)))\n",
    "    df = pd.read_csv(fname)\n",
    "    df['sector'] = sector\n",
    "    dfs.append(df)\n",
    "cyclone = pd.concat(dfs).set_index(['sector','region_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_rp, cyclone_exp = split_df_by_rp_columns(cyclone)\n",
    "\n",
    "cyclone_rp = tidy_df(\n",
    "    cyclone_rp, \n",
    "    id_vars=['region_name', 'sector'], \n",
    "    new_id_vars=['hazard', 'rp'])\n",
    "cyclone_rp['rcp'] = 'historical'\n",
    "cyclone_rp['gcm'] = 'none'\n",
    "cyclone_rp['epoch'] = 'HIST'\n",
    "\n",
    "cyclone_exp = tidy_df(\n",
    "    cyclone_exp, \n",
    "    id_vars=['region_name', 'sector'], \n",
    "    new_id_vars=['hazard'])\n",
    "cyclone_exp['rcp'] = 'historical'\n",
    "cyclone_exp['gcm'] = 'none'\n",
    "cyclone_exp['epoch'] = 'HIST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-thanks",
   "metadata": {},
   "source": [
    "## Flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = defaultdict(list)\n",
    "for fname in tqdm(fluvial_fnames):\n",
    "    climate = os.path.basename(os.path.dirname(fname))\n",
    "    sector = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(fname))))\n",
    "    df = pd.read_csv(fname)\n",
    "    df['sector'] = sector\n",
    "    df['rcp'] = climate\n",
    "    dfs[climate].append(df)\n",
    "fluvial_hist = pd.concat(dfs['historical']).set_index(['region_name','sector','rcp'])\n",
    "fluvial_fut  = pd.concat(dfs['rcp4p5'] + dfs['rcp8p5']).set_index(['region_name','sector','rcp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_fut_rp, fluvial_fut_exp = split_regroup(fluvial_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_hist_rp, fluvial_hist_exp = split_regroup(fluvial_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_rp = fluvial_hist_rp.append(fluvial_fut_rp)\n",
    "fluvial_rp.epoch.replace('1980', 'HIST', inplace=True) \n",
    "fluvial_rp['hazard'] = 'fluvial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_exp = fluvial_hist_exp.append(fluvial_fut_exp)\n",
    "fluvial_exp.epoch.replace('1980', 'HIST', inplace=True) \n",
    "fluvial_exp['hazard'] = 'fluvial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-proof",
   "metadata": {},
   "source": [
    "## Coastal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = defaultdict(list)\n",
    "for fname in tqdm(coastal_fnames):\n",
    "    climate = os.path.basename(os.path.dirname(fname))\n",
    "    sector = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(fname))))\n",
    "    df = pd.read_csv(fname)\n",
    "    df['sector'] = sector\n",
    "    df['rcp'] = climate\n",
    "    dfs[climate].append(df)\n",
    "coastal_hist = pd.concat(dfs['historical']).set_index(['region_name','sector','rcp'])\n",
    "coastal_fut  = pd.concat(dfs['rcp4p5_perc_50'] + dfs['rcp8p5_perc_50']).set_index(['region_name','sector','rcp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_fut_rp, coastal_fut_exp = split_regroup(coastal_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_hist_rp, coastal_hist_exp = split_regroup(coastal_hist)\n",
    "coastal_hist_rp = coastal_hist_rp[coastal_hist_rp.epoch == 'HIST']\n",
    "coastal_hist_exp = coastal_hist_exp[coastal_hist_exp.epoch == 'HIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_rp = coastal_hist_rp.append(coastal_fut_rp)\n",
    "# above processing coded the subsidence scenario in the GCM column\n",
    "# pick only \"WS\" - with subsidence\n",
    "coastal_rp = coastal_rp[coastal_rp.gcm == 'WS'].copy()\n",
    "coastal_rp.gcm = 'none'\n",
    "coastal_rp.rcp = coastal_rp.rcp.str.replace('_perc_50', '')\n",
    "coastal_rp['hazard'] = 'coastal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_exp = coastal_hist_exp.append(coastal_fut_exp)\n",
    "# above processing coded the subsidence scenario in the GCM column\n",
    "# pick only \"WS\" - with subsidence\n",
    "coastal_exp = coastal_exp[coastal_exp.gcm == 'WS'].copy()\n",
    "coastal_exp.gcm = 'none'\n",
    "coastal_exp.rcp = coastal_exp.rcp.str.replace('_perc_50', '')\n",
    "coastal_exp['hazard'] = 'coastal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-alcohol",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.concat([cyclone_exp, fluvial_exp, coastal_exp]) \\\n",
    "    .drop(columns=[\"EAEL-primary-gdp\", \"EAEL-secondary-gdp\", \"EAEL-tertiary-gdp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for disruption\n",
    "exp['EAEL-gdp'] = exp['EAEL-gdp'] * 30 / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all = exp.rename(columns={\n",
    "    \"region_name\": \"GID_1\",\n",
    "    \"rp\": \"return_period__years\",\n",
    "    \"expectedLengthDamaged\": \"expected_length_damaged__km\",\n",
    "    \"EAEL-gdp\": \"expected_indirect_damage__million_USD\",\n",
    "    \"maxEAD\": \"max_expected_direct_damage__million_USD\",\n",
    "    \"minEAD\": \"min_expected_direct_damage__million_USD\",\n",
    "    \"rcp\": \"representative_concentration_pathway\",\n",
    "    \"gcm\": \"global_climate_model\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_0 = exp_all.GID_1.apply(lambda d: d.split(\".\")[0])\n",
    "exp_all.insert(1, 'GID_0', gid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all.to_csv('../results/expected_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max over climate models\n",
    "# then sum over sector, hazard\n",
    "exp_all_summary = exp_all \\\n",
    "    .groupby(['GID_0', 'GID_1', 'sector', 'hazard', 'representative_concentration_pathway', 'epoch']) \\\n",
    "    .max() \\\n",
    "    .reset_index() \\\n",
    "    .drop(\n",
    "        columns=[\n",
    "            'global_climate_model', 'hazard'\n",
    "        ]) \\\n",
    "    .groupby(['GID_0', 'GID_1', 'representative_concentration_pathway', 'epoch']) \\\n",
    "    .sum() \\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all_summary.to_csv('../results/expected_all_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all[(exp_all.GID_1 == 'IDN.10_1') & (exp_all.epoch == '2030') & (exp_all.representative_concentration_pathway == 'rcp8p5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all_summary[exp_all_summary.GID_1 == 'IDN.10_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = pd.concat([cyclone_rp, fluvial_rp, coastal_rp]) \\\n",
    "    .drop(columns=[\"primary-gdp\", \"secondary-gdp\", \"tertiary-gdp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now corrected in data\n",
    "# correct for units error - should be in US$m to match expected GDP\n",
    "#rp.gdp = rp.gdp * 1e6\n",
    "\n",
    "# account for disruption\n",
    "rp.gdp = rp.gdp * 30 / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_all = rp.rename(columns={\n",
    "    \"region_name\": \"GID_1\",\n",
    "    \"rp\": \"return_period__years\",\n",
    "    \"assetDamage\": \"length_damaged__km\",\n",
    "    \"gdp\": \"indirect_damage__million_USD\",\n",
    "    \"maxEventCost\": \"max_direct_damage__million_USD\",\n",
    "    \"minEventCost\": \"min_direct_damage__million_USD\",\n",
    "    \"rcp\": \"representative_concentration_pathway\",\n",
    "    \"gcm\": \"global_climate_model\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_0 = rp_all.GID_1.apply(lambda d: d.split(\".\")[0])\n",
    "rp_all.insert(1, 'GID_0', gid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_all.to_csv('../results/rp_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_LAO = rp_all[rp_all.GID_0 == 'LAO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_LAO.to_csv('../results/rp_LAO.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-louisville",
   "metadata": {},
   "source": [
    "Some sense-checking of numbers of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rp.region_name.unique()) # total regions should be 312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.groupby(['hazard', 'rp']).count().reset_index()[['hazard', 'rp']].groupby('hazard').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.groupby(['hazard', 'sector', 'rcp', 'gcm', 'epoch']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "2940 / 10, 8736 / 28, 2808 / 9  # 294 is okay for coastal, excludes LAO regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.groupby(['hazard', 'sector', 'rcp', 'gcm', 'epoch']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-wilson",
   "metadata": {},
   "source": [
    "Historical - one row per region, sum over sectors and hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_exp = exp[exp.epoch=='HIST'] \\\n",
    "    .drop(\n",
    "        columns=[\n",
    "            'rcp', 'gcm', 'epoch', 'hazard'\n",
    "        ]) \\\n",
    "    .groupby(['region_name']) \\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[exp.region_name == 'IDN.10_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max over climate models\n",
    "# then sum over sector, hazard\n",
    "fut_exp = exp[exp.epoch=='2080'] \\\n",
    "    .groupby(['region_name', 'sector', 'hazard', 'rcp']) \\\n",
    "    .max() \\\n",
    "    .reset_index() \\\n",
    "    .drop(\n",
    "        columns=[\n",
    "            'gcm', 'epoch', 'hazard'\n",
    "        ]) \\\n",
    "    .groupby(['region_name', 'rcp']) \\\n",
    "    .sum() \\\n",
    "    .reset_index() \\\n",
    "    .pivot(index='region_name', columns='rcp', values=['EAEL-gdp','expectedLengthDamaged','maxEAD','minEAD'])\n",
    "fut_exp.columns = [f\"{col}_{rcp}\" for col, rcp in fut_exp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp = hist_exp.merge(fut_exp, on='region_name')\n",
    "all_exp.index.name = 'GID_1'\n",
    "all_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp.to_csv('../results/expected_summary.csv')\n",
    "len(all_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-adaptation",
   "metadata": {},
   "source": [
    "prob-loss direct/indirect - historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_summary(rp, region_name):\n",
    "    region_rp = rp[rp.region_name == region_name]\n",
    "    region_rp = region_rp[region_rp.epoch == 'HIST']\n",
    "    region_rp = region_rp[region_rp.rp.isin([10,50,100,500,1000])]\n",
    "    region_rp = region_rp[['rp', 'minEventCost', 'gdp']] \\\n",
    "        .groupby('rp') \\\n",
    "        .sum() \\\n",
    "        .reset_index()\n",
    "    \n",
    "    region_rp = region_rp \\\n",
    "        .rename(columns={\n",
    "            'gdp': '1. Economic impact',\n",
    "            'minEventCost': '2. Direct damages',\n",
    "        }) \\\n",
    "        .melt(id_vars='rp', var_name='field')\n",
    "    region_rp['probability'] = 1 / region_rp.rp\n",
    "    return region_rp.drop(columns='rp') \\\n",
    "        .sort_values(by=['field', 'probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../results/historical_total\n",
    "!mkdir -p ../results/regional_breakdown\n",
    "!mkdir -p ../results/climate_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_name in tqdm(rp.region_name.unique()):\n",
    "    region_summary(rp, region_name).to_csv(f\"../results/historical_total/historical_total_{region_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_breakdown(rp, region_name):\n",
    "    region_rp = rp[rp.region_name == region_name].copy()\n",
    "    region_rp['probability'] = 1 / region_rp.rp\n",
    "\n",
    "    region_rp = region_rp.drop(columns=['region_name', 'assetDamage', 'rp', 'gcm'])\n",
    "    region_rp = region_rp.groupby(['sector', 'hazard', 'rcp', 'epoch', 'probability']) \\\n",
    "        .agg(['min', 'max'])\n",
    "    region_rp.columns = [f\"{var}_{agg}\" for var, agg in region_rp.columns]\n",
    "    return region_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_name in tqdm(rp.region_name.unique()):\n",
    "    region_breakdown(rp, region_name).to_csv(f\"../results/regional_breakdown/regional_breakdown_{region_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regional_total_by_climate(rp, region_name):\n",
    "    region_rp = rp[rp.region_name == region_name].copy()\n",
    "    region_rp['probability'] = 1 / region_rp.rp\n",
    "    region_rp = region_rp[region_rp.rp.isin([10,50,100,500,1000])]\n",
    "    region_rp = region_rp[region_rp.epoch.isin(['HIST', '2080'])]\n",
    "    region_rp = region_rp.drop(columns=['region_name', 'rp', 'gcm'])\n",
    "    region_rp = region_rp.groupby(['sector', 'hazard', 'rcp', 'epoch', 'probability']).max().reset_index()\n",
    "    region_rp = region_rp.groupby(['hazard', 'rcp', 'epoch', 'probability']).sum()\n",
    "    region_rp['minTotalDamage'] = region_rp.minEventCost + region_rp.gdp\n",
    "    region_rp['maxTotalDamage'] = region_rp.maxEventCost + region_rp.gdp\n",
    "    return region_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_name in tqdm(rp.region_name.unique()):\n",
    "    regional_total_by_climate(rp, region_name).to_csv(f\"../results/climate_total/climate_total_{region_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(region_name)\n",
    "regional_total_by_climate(rp, region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-supplement",
   "metadata": {},
   "source": [
    "Sense-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rp[(rp.region_name == 'IDN.10_1')& (rp.sector=='Road') & (rp.hazard=='fluvial') & (rp.gcm =='WATCH')].copy()\n",
    "df['prob'] = 1 / df.rp\n",
    "df = df.sort_values(by='prob')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.trapz(df.gdp, df.prob), np.trapz(df.maxEventCost, df.prob), np.trapz(df.minEventCost, df.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[(exp.region_name == 'IDN.10_1')& (exp.sector=='Road') & (exp.hazard=='fluvial') & (exp.gcm =='WATCH')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
